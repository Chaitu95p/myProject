Mapreduce Advanced Concepts (05-27 NS)


•	Coding Efficiency			In Developers Hand
•	Configuration Properties		In Admin Hands
•	Cluster Hardware		 	In Infrastructure Team Hands

 	No.of Containers = No.of tasks we can able to run in parallel.

Eg: 48 Containers means, we’ve a capacity of running 48 tasks in parallel.

256 GB Ram in Node	=	32 GB for Linux OS + 32 GB for HBase + 64 GB for Impala + Rest of the RAM i.e,. 128 GB ram for YARN.

24 Cores 	 48 Vcores	48 Containers

•	In general all nodes have same configurations in the cluster.

YARN Job Anatomy:
----------------

Client
Resource Manager
Node Manager
MapReduce Application Master
HDFS

* Client submits a MR job(i.e., .jar file)
* Job will get submitted to ResourceManager(RM runs on 8032 IPC Port)
* Get the Job ID (job_epoch timestamp from RM started_seq number) eg. (job_1462348973456_0001)
* Once it gets Job ID, It'll Copies Job Resources(.JAR file and dependent .jar files are copied from LFS to HDFS /tmp dir) to HDFS
* ResourceManager identifies one NodeManager on which some containers will available and inside container tasks will run.
* NodeManager launches AppMaster.
* Retrieve InputSplits from HDFS.
* AppMaster requests resources to ResourceManager.

NOTE: For one job one AppMaster will be there.
      If you have 100 jobs parallely running on your cluster then 100 AppMasters will be there.
